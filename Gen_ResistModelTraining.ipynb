{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7z5WOFPl2GX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool\n",
        "import pickle\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please run this after the scrapping code and downloading the data"
      ],
      "metadata": {
        "id": "2TcGjGJdmCSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"amr_dataset_500\"\n",
        "GRAPH_DATA_DIR = os.path.join(BASE_DIR, \"graph_data\")\n"
      ],
      "metadata": {
        "id": "GXSX3uF6l_m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Clear GPU cache\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "Ns4ZVMcUmWZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "VPZxryQImceu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(GRAPH_DATA_DIR, \"graphs.pkl\"), \"rb\") as f:\n",
        "    graphs_raw = pickle.load(f)\n",
        "\n",
        "graphs = []\n",
        "for g in graphs_raw:\n",
        "    graphs.append(\n",
        "        Data(\n",
        "            x=torch.tensor(g[\"x\"], dtype=torch.long),\n",
        "            edge_index=torch.tensor(g[\"edge_index\"], dtype=torch.long),\n",
        "            y=torch.tensor(g[\"y\"], dtype=torch.float32).unsqueeze(0),\n",
        "            card=torch.tensor(g[\"card\"], dtype=torch.float32).unsqueeze(0),\n",
        "            genome_feat=torch.tensor(g.get(\"genome_feat\", np.zeros(3)), dtype=torch.float32).unsqueeze(0),\n",
        "        )\n",
        "    )\n",
        "\n",
        "with open(os.path.join(GRAPH_DATA_DIR, \"genome_ids.json\"), \"r\") as f:\n",
        "    genome_ids = json.load(f)\n",
        "with open(os.path.join(GRAPH_DATA_DIR, \"antibiotics.json\"), \"r\") as f:\n",
        "    antibiotics = json.load(f)\n",
        "with open(os.path.join(GRAPH_DATA_DIR, \"kmer_vocab.json\"), \"r\") as f:\n",
        "    kmer_vocab = json.load(f)\n",
        "with open(os.path.join(GRAPH_DATA_DIR, \"card_genes.json\"), \"r\") as f:\n",
        "    card_genes = json.load(f)[\"genes\"]\n",
        "\n",
        "print(f\"Loaded {len(graphs)} samples\")"
      ],
      "metadata": {
        "id": "aeoiGr-AmXiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Weights"
      ],
      "metadata": {
        "id": "T6vko_bIml5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_all = torch.stack([g.y.squeeze(0) for g in graphs])\n",
        "pos_weights = []\n",
        "for i in range(labels_all.shape[1]):\n",
        "    pos = labels_all[:, i].sum()\n",
        "    neg = len(labels_all) - pos\n",
        "    weight = max(neg / (pos + 1e-6), 0.1)\n",
        "    pos_weights.append(min(weight, 10.0))\n",
        "pos_weights = torch.tensor(pos_weights, dtype=torch.float32).to(device)\n"
      ],
      "metadata": {
        "id": "VGHxpOl3mgxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split"
      ],
      "metadata": {
        "id": "3esRjRrlmscn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(graphs))\n",
        "val_size = int(0.15 * len(graphs))\n",
        "\n",
        "train_dataset = graphs[:train_size]\n",
        "val_dataset = graphs[train_size:train_size + val_size]\n",
        "test_dataset = graphs[train_size + val_size:]\n",
        "\n",
        "print(f\"\\nDataset split: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "\n",
        "#Smaller batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4)\n"
      ],
      "metadata": {
        "id": "Ghwl8arvmoee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "T2tbscKVnXfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryEfficientGAT(nn.Module):\n",
        "    def __init__(self, num_kmers, kmer_emb_dim=64, gat_hidden=128, gat_heads=4,\n",
        "                 card_feat_dim=len(card_genes), genome_feat_dim=3, num_classes=len(antibiotics)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kmer_emb = nn.Embedding(num_kmers, kmer_emb_dim)\n",
        "\n",
        "        self.gat1 = GATConv(kmer_emb_dim, gat_hidden // gat_heads, heads=gat_heads, dropout=0.3)\n",
        "        self.gat2 = GATConv(gat_hidden, gat_hidden, heads=1, concat=False, dropout=0.3)\n",
        "\n",
        "        self.card_mlp = nn.Sequential(\n",
        "            nn.Linear(card_feat_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.genome_mlp = nn.Sequential(\n",
        "            nn.Linear(genome_feat_dim, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        combined_dim = gat_hidden * 2 + 32 + 16\n",
        "\n",
        "        self.final_mlp = nn.Sequential(\n",
        "            nn.Linear(combined_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch, card, genome_feat):\n",
        "        x = self.kmer_emb(x).squeeze(1)\n",
        "\n",
        "        x = F.elu(self.gat1(x, edge_index))\n",
        "        x = F.elu(self.gat2(x, edge_index))\n",
        "\n",
        "        x_mean = global_mean_pool(x, batch)\n",
        "        x_max = global_max_pool(x, batch)\n",
        "        x_graph = torch.cat([x_mean, x_max], dim=1)\n",
        "\n",
        "        card_feat = self.card_mlp(card)\n",
        "        genome_embed = self.genome_mlp(genome_feat)\n",
        "\n",
        "        combined = torch.cat([x_graph, card_feat, genome_embed], dim=1)\n",
        "        out = self.final_mlp(combined)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = MemoryEfficientGAT(num_kmers=len(kmer_vocab[\"kmer2idx\"])).to(device)\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)"
      ],
      "metadata": {
        "id": "o8c4aai-muYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixed precision scaler"
      ],
      "metadata": {
        "id": "545uzS3Snjj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = GradScaler()\n",
        "\n",
        "def compute_metrics(output, target):\n",
        "    probs = torch.sigmoid(output).cpu().numpy()\n",
        "    preds = (probs > 0.5).astype(float)\n",
        "    target_np = target.cpu().numpy()\n",
        "    acc = (preds == target_np).mean()\n",
        "    try:\n",
        "        auc = roc_auc_score(target_np, probs, average='macro')\n",
        "    except:\n",
        "        auc = 0.0\n",
        "    return acc, auc\n",
        "\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision forward\n",
        "        with autocast():\n",
        "            out = model(batch.x, batch.edge_index, batch.batch, batch.card, batch.genome_feat)\n",
        "            loss = criterion(out, batch.y)\n",
        "\n",
        "        # Scaled backward\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "        # Clear cache periodically\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def eval_epoch(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                out = model(batch.x, batch.edge_index, batch.batch, batch.card, batch.genome_feat)\n",
        "                loss = criterion(out, batch.y)\n",
        "\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "            all_outputs.append(out.cpu())\n",
        "            all_targets.append(batch.y.cpu())\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs, dim=0)\n",
        "    all_targets = torch.cat(all_targets, dim=0)\n",
        "\n",
        "    acc, auc = compute_metrics(all_outputs, all_targets)\n",
        "\n",
        "    return total_loss / len(loader.dataset), acc, auc\n",
        "\n",
        "print(\"\\n training\\n\")\n",
        "EPOCHS = 30\n",
        "best_val_auc = 0\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train_epoch()\n",
        "    val_loss, val_acc, val_auc = eval_epoch(val_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val_auc = val_auc\n",
        "        torch.save(model.state_dict(), f\"{BASE_DIR}/best_model.pt\")\n",
        "        print(f\"Best model saved (AUC: {val_auc:.4f})\")\n",
        "\n",
        "    # Clear cache after each epoch\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n Training complete!\")\n",
        "model.load_state_dict(torch.load(f\"{BASE_DIR}/best_model.pt\"))\n",
        "test_loss, test_acc, test_auc = eval_epoch(test_loader)\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"   Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"   ROC-AUC:  {test_auc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QvM23sIQnlzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LXYL9puSnuHO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}